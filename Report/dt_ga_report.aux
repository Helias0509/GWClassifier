\relax 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\@writefile{toc}{\contentsline {paragraph}{}{i}{section*.3}}
\@writefile{toc}{\contentsline {section}{ACKNOWLEDGEMENT}{i}{section*.5}}
\@writefile{toc}{\contentsline {section}{ABSTRACT}{ii}{section*.6}}
\@writefile{toc}{\contentsline {section}{CONTENTS}{ii}{section*.6}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}INTRODUCTION}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}SCOPE}{1}{section.1.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}REQUIREMENT SPECIFICATION}{3}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsubsection}{Software Requirements}{3}{section*.8}}
\@writefile{toc}{\contentsline {subsubsection}{Hardware Requirements}{3}{section*.9}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Decision Tree Learning}{4}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}A Naive Approach}{4}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Definition}{4}{section.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}The Basic Idea}{5}{section.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Sample Decision Tree\relax }}{5}{figure.caption.10}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:logo2}{{3.1}{5}{Sample Decision Tree\relax \relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Building the Decision Tree}{6}{section.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}ID3 Algorithm}{6}{subsection.3.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces ID3 Algorithm\relax }}{7}{figure.caption.11}}
\newlabel{fig:ID3}{{3.2}{7}{ID3 Algorithm\relax \relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Choosing the best attribute for a given node}{7}{subsection.3.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Entropy - a measure of homogeneity of the set of examples}{8}{subsection.3.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces The entropy function relative to a binary classification, as the proportion of positive examples p$_{p}$ varies between 0 and 1.\relax }}{9}{figure.caption.12}}
\newlabel{fig:ID3}{{3.3}{9}{The entropy function relative to a binary classification, as the proportion of positive examples p$_{p}$ varies between 0 and 1.\relax \relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Information gain measures the expected reduction in entropy}{9}{subsection.3.4.4}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}An Example}{11}{section.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}An Example: "go go gophers"}{11}{subsection.3.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Example Encoding Table}{11}{subsection.3.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Encoded String}{11}{subsection.3.5.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Genetic Algorithms}{12}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Storing the Huffman Tree}{12}{section.4.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Creating the Huffman Table}{13}{section.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Storing Sizes}{14}{section.4.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}CONCLUSION AND FUTURE WORKS}{15}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{test}{1}
\bibcite{t}{2}
\bibcite{t}{3}
\bibcite{t}{4}
\bibcite{t}{5}
\bibcite{t}{6}
\@writefile{toc}{\contentsline {section}{BIBLIOGRAPHY}{17}{Item.12}}
\@writefile{toc}{\contentsline {section*}{APPENDICES}{18}{chapter*.15}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Application Window - Welcome Screen\relax }}{19}{figure.caption.19}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Decision Tree Constructor Window.\relax }}{19}{figure.caption.20}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Decision Tree Classifier Window.\relax }}{20}{figure.caption.21}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Decision Tree Construction with GA based Feature Selector.\relax }}{20}{figure.caption.22}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Decision Tree Construction with manual feature selection.\relax }}{21}{figure.caption.23}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces The project source code on github public repository.\relax }}{21}{figure.caption.24}}
